{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64433cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd218151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle for most common words \n",
    "most_common_words = pd.read_pickle('/Users/lihuicham/Desktop/Y2S2/BT4222/project/standup-comedy-analysis/main/pickle/common_words_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bec9479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    350\n",
      "0     65\n",
      "Name: Polarity_Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load pickle for textblob dataframe \n",
    "df_textblob = pd.read_pickle('/Users/lihuicham/Desktop/Y2S2/BT4222/project/standup-comedy-analysis/main/pickle/sentiments_textblob.pkl')\n",
    "print(df_textblob['Polarity_Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94aff32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    308\n",
      "0    107\n",
      "Name: Polarity_Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load pickle for vader dataframe \n",
    "df_vader = pd.read_pickle('/Users/lihuicham/Desktop/Y2S2/BT4222/project/standup-comedy-analysis/main/pickle/sentiments_vader.pkl')\n",
    "print(df_vader['Polarity_Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06666ee",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b4d557a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comedian</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Polarity_Score</th>\n",
       "      <th>Subjectivity_Score</th>\n",
       "      <th>Polarity_Class</th>\n",
       "      <th>Subjectivity_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Rock</td>\n",
       "      <td>March 8, 2023</td>\n",
       "      <td>Selective Outrage (2023) | Transcript</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lets go    she said  ill do anything you w...</td>\n",
       "      <td>0.053924</td>\n",
       "      <td>0.537392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marc Maron</td>\n",
       "      <td>March 3, 2023</td>\n",
       "      <td>Thinky Pain (2013) | Transcript</td>\n",
       "      <td>Marc Maron returns to his old stomping grounds...</td>\n",
       "      <td>i dont know what you were thinking like im no...</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>0.527340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chelsea Handler</td>\n",
       "      <td>March 3, 2023</td>\n",
       "      <td>Evolution (2020) | Transcript</td>\n",
       "      <td>Chelsea Handler is back and better than ever -...</td>\n",
       "      <td>join me in welcoming the author of six number ...</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.496281</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tom Papa</td>\n",
       "      <td>March 3, 2023</td>\n",
       "      <td>What A Day! (2022) | Transcript</td>\n",
       "      <td>Follows Papa as he shares about parenting, his...</td>\n",
       "      <td>premiered on december   ladies and gentlemen g...</td>\n",
       "      <td>0.040564</td>\n",
       "      <td>0.541739</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jim Jefferies</td>\n",
       "      <td>February 22, 2023</td>\n",
       "      <td>High n’ Dry (2023) | Transcript</td>\n",
       "      <td>Jim Jefferies is back and no topic is off limi...</td>\n",
       "      <td>please welcome to the stage jim jefferies hell...</td>\n",
       "      <td>0.059485</td>\n",
       "      <td>0.540981</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Comedian               Date                                  Title  \\\n",
       "0       Chris Rock      March 8, 2023  Selective Outrage (2023) | Transcript   \n",
       "1       Marc Maron      March 3, 2023        Thinky Pain (2013) | Transcript   \n",
       "2  Chelsea Handler      March 3, 2023          Evolution (2020) | Transcript   \n",
       "3         Tom Papa      March 3, 2023        What A Day! (2022) | Transcript   \n",
       "4    Jim Jefferies  February 22, 2023        High n’ Dry (2023) | Transcript   \n",
       "\n",
       "                                            Subtitle  \\\n",
       "0                                                NaN   \n",
       "1  Marc Maron returns to his old stomping grounds...   \n",
       "2  Chelsea Handler is back and better than ever -...   \n",
       "3  Follows Papa as he shares about parenting, his...   \n",
       "4  Jim Jefferies is back and no topic is off limi...   \n",
       "\n",
       "                                          Transcript  Polarity_Score  \\\n",
       "0      lets go    she said  ill do anything you w...        0.053924   \n",
       "1   i dont know what you were thinking like im no...        0.039222   \n",
       "2  join me in welcoming the author of six number ...        0.028674   \n",
       "3  premiered on december   ladies and gentlemen g...        0.040564   \n",
       "4  please welcome to the stage jim jefferies hell...        0.059485   \n",
       "\n",
       "   Subjectivity_Score  Polarity_Class  Subjectivity_Class  \n",
       "0            0.537392               1                   1  \n",
       "1            0.527340               1                   1  \n",
       "2            0.496281               1                   0  \n",
       "3            0.541739               1                   1  \n",
       "4            0.540981               1                   1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textblob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafab12",
   "metadata": {},
   "source": [
    "## Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8770a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes of the positive and negative classes\n",
    "pos_indexes = df_textblob.index[df_textblob['Polarity_Class'] == 1].tolist()\n",
    "neg_indexes = df_textblob.index[df_textblob['Polarity_Class'] == 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24306ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Positive Words : 10500\n",
      "Number of Negative Words : 1950\n"
     ]
    }
   ],
   "source": [
    "# find out how many positive and negative words we have in total, along with their frequency (word, frequency)\n",
    "pos_words_tuple = []\n",
    "neg_words_tuple = []\n",
    "\n",
    "for key in pos_indexes : \n",
    "    word_list = most_common_words[key]\n",
    "    for word in word_list :\n",
    "        pos_words_tuple.append(word)\n",
    "        \n",
    "for key in neg_indexes : \n",
    "    word_list = most_common_words[key]\n",
    "    for word in word_list :\n",
    "        neg_words_tuple.append(word)\n",
    "        \n",
    "print(f\"Number of Positive Words : {len(pos_words_tuple)}\" )\n",
    "print(f\"Number of Negative Words : {len(neg_words_tuple)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b362d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the based on descending frequency  (most frequent to least frequent)\n",
    "sorted_pos_words = sorted(pos_words_tuple, key=lambda w: w[1], reverse=True)\n",
    "sorted_neg_words = sorted(neg_words_tuple, key=lambda w: w[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436f7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = [w[0] for w in sorted_pos_words]\n",
    "neg_words = [w[0] for w in sorted_neg_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c1066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 666 words that exists in both positive and negative word list.\n"
     ]
    }
   ],
   "source": [
    "# create UNIQUE positive and negative word list \n",
    "\n",
    "# first, find the common words between both lists\n",
    "common_list = list(set(pos_words) & set(neg_words))\n",
    "print(f\"There are {len(common_list)} words that exists in both positive and negative word list.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c37cdf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Positive Words : 6583\n",
      "Number of Unique Negative Words : 573\n"
     ]
    }
   ],
   "source": [
    "# remove the common words to create unique lists \n",
    "pos_unique_words = [w for w in pos_words if w not in common_list]\n",
    "neg_unique_words = [w for w in neg_words if w not in common_list]\n",
    "\n",
    "print(f\"Number of Unique Positive Words : {len(pos_unique_words)}\" )\n",
    "print(f\"Number of Unique Negative Words : {len(neg_unique_words)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a659124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more cleaning : remove stop words\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# filtered_pos_unique_words = [w for w in pos_unique_words if w not in stop_words]\n",
    "# filtered_neg_unique_words = [w for w in neg_unique_words if w not in common_list]\n",
    "\n",
    "# print(f\"Number of Filtered Unique Positive Words : {len(filtered_pos_unique_words)}\" )   # 6579\n",
    "# print(f\"Number of Filtered Unique Negative Words : {len(filtered_neg_unique_words)}\" )   # 573\n",
    "\n",
    "# from this result, we know that removing stop words is not very useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16fe82fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Positive Words with No Duplicates : 4543\n",
      "Number of Unique Negative Words with No Duplicates : 552\n"
     ]
    }
   ],
   "source": [
    "# notice that there are actually a lot of repeated word in each list, \n",
    "# especially in the positive words list. \n",
    "# let's try to remove the duplicates \n",
    "# every word should only exist once within its own list (no duplicates)\n",
    "\n",
    "# Note : we cannot use the set() function to remove duplicate as the method does not preserve the sorted order. \n",
    "\n",
    "pos_no_dup = []\n",
    "neg_no_dup = []\n",
    "\n",
    "for word in pos_unique_words:\n",
    "    if word not in pos_no_dup:\n",
    "        pos_no_dup.append(word)\n",
    "\n",
    "for word in neg_unique_words:\n",
    "    if word not in neg_no_dup:\n",
    "        neg_no_dup.append(word)\n",
    "\n",
    "print(f\"Number of Unique Positive Words with No Duplicates : {len(pos_no_dup)}\" )\n",
    "print(f\"Number of Unique Negative Words with No Duplicates : {len(neg_no_dup)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71a06fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "own_stop_words = ['♫', 'fucken', 'motherfcker', 'whaaaaaaaa', \n",
    "                  'whaaaaaaaaaaaaaaaa', 'mmmmm', 'i–i', 'up♪', 'like—', '♪girl',\n",
    "                 'yeah♪', 'you-', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a019dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Filtered Positive Words : 4536\n",
      "Number of Filtered Negative Words : 548\n"
     ]
    }
   ],
   "source": [
    "filtered_pos_words = [w for w in pos_no_dup if w not in own_stop_words]\n",
    "filtered_neg_words = [w for w in neg_no_dup if w not in own_stop_words]\n",
    "\n",
    "print(f\"Number of Filtered Positive Words : {len(filtered_pos_words)}\" )  \n",
    "print(f\"Number of Filtered Negative Words : {len(filtered_neg_words)}\" )  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
